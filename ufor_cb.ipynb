{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preparation\n",
                "\n",
                "In a first step, we load or activate the packages.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(dplyr)\n",
                "library(stringr)\n",
                "library(tidyr)\n",
                "library(quanteda)\n",
                "library(here)\n",
                "library(openxlsx)\n",
                "library(knitr)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 1: Computational extraction of all potential instances of utterance-final *or*\n",
                "\n",
                "This section extracts potential instances or candidate examples of utterance-final *or* (UF-or) from four spoken corpora:\n",
                "\n",
                "* [Australian Radio Talkback](https://www.ausnc.org.au/corpora/art)\n",
                "\n",
                "* [Griffith Corpus of Spoken Australian English](https://www.ausnc.org.au/corpora/gcsause)\n",
                "\n",
                "* [Monash corpus](https://www.ausnc.org.au/corpora/monash)\n",
                "\n",
                "* [The La Trobe Corpus of Spoken Australian English](https://www.ausnc.org.au/corpora/latrobecsause)\n",
                "\n",
                "## Loading data\n",
                "\n",
                "The corpora were downloaded and stored in a directory (folder) called `data`. To load the data, we define the paths to the files containing the transcripts (which are located in the `data` folder in the specific sub-directories for the corpora).\n",
                "\n",
                ">\n",
                "> **NOTE**: DO NOT EXECUTE THE CODE CHUNKS BELOW! IT IS DISPLAYED FOR TRANSPARENCY REASONS ONLY! THE DATA IS NOT MADE AVAILABLE FOR COPYRIGHT REASONS! \n",
                ">\n",
                "> **THE INTERACTIVE CODE (CODE THAT IS EXECUTABLE) STARTS WITH THE SECTION \"INTERACTIVE CODE BELOW\"**\n",
                ">\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fart <- list.files(here::here(\"data\", \"Australian Radio Talkback/files/Raw\"), full.names = T)\n",
                "fgri <- list.files(here::here(\"data\", \"Griffith Corpus of Spoken Australian English/files/Raw\"), \n",
                "                        pattern = \".txt\", full.names = T)\n",
                "fmon <- list.files(here::here(\"data\", \"Monash/files/Text\"), \n",
                "                        pattern = \".txt\", full.names = T)\n",
                "flat <- list.files(here::here(\"data\", \"The La Trobe Corpus of Spoken Australian English/files/Raw\"), \n",
                "                        pattern = \".txt\", full.names = T)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now check if we have the paths to the data by inspecting the first six paths of files in the *Australian Radio Talkback* corpus.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "head(fart)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic01.JPG?raw=true)\n",
                "\n",
                "We now proceed by loading and processing (cleaning) the data.\n",
                "\n",
                "### Load ART\n",
                "\n",
                "We start with the  content of the *Australian Radio Talkback* corpus (art).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load raw content\n",
                "vart <- sapply(fart, function(x){\n",
                "  # read in content of the file\n",
                "  x <- readLines(x)\n",
                "  # remove empty rows\n",
                "  x <- x[x != \"\"]\n",
                "  })\n",
                "# unlist the object containing the corpus data\n",
                "arttext <- unlist(vart)\n",
                "# collapse into a data frame\n",
                "artdf <- data.frame(names(arttext), names(arttext),arttext) %>%\n",
                "  # rename columns\n",
                "  dplyr::rename(corpus = colnames(.)[1],\n",
                "                file = colnames(.)[2],\n",
                "                text = colnames(.)[3]) %>%\n",
                "  # create new columns containing corpus, file, and speaker information as well as a column with clean content\n",
                "  dplyr::mutate(\n",
                "    # extract corpus name\n",
                "    corpus = stringr::str_replace_all(corpus, \".*data/(.*?)/.*\", \"\\\\1\"),\n",
                "    # extract file name\n",
                "    file = stringr::str_replace_all(file, \".*Raw/(.*?)-raw.*\", \"\\\\1\"),\n",
                "    # extract speaker\n",
                "    speaker = stringr::str_replace_all(text, \"\\\\[(.*?)\\\\].*\", \"\\\\1\"),\n",
                "    # clean transcripts\n",
                "    textclean = stringr::str_remove_all(text, \".*?\\\\]\"),\n",
                "    # remove superfluous white spaces\n",
                "    textclean = stringr::str_squish(textclean))\n",
                "# remove row names\n",
                "rownames(artdf) <- NULL\n",
                "# inspect\n",
                "knitr::kable(head(artdf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic02.JPG?raw=true)\n",
                "\n",
                "### Load GRI\n",
                "\n",
                "We continue with the content of the files of the *Griffith Corpus of Spoken Australian English* (gri).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vgri <- sapply(fgri, function(x){\n",
                "  x <- readLines(x, encoding = \"UTF-8\")\n",
                "  x <- x[x != \"\"]\n",
                "  x <- x[!stringr::str_detect(x, \"\\\\|.*\\\\|\")]\n",
                "  x <- paste0(x, collapse = \" \")\n",
                "  x <- stringr::str_split(stringr::str_replace_all(x, \"( [A-Z]:)\", \"qwertz\\\\1\"), \"qwertz\")\n",
                "  x <- unlist(x)\n",
                "  x <- stringr::str_squish(x)\n",
                "})\n",
                "gritext <- unlist(vgri)\n",
                "# collapse into df\n",
                "gridf <- data.frame(names(gritext), names(gritext),gritext) %>%\n",
                "  dplyr::rename(corpus = colnames(.)[1],\n",
                "                file = colnames(.)[2],\n",
                "                text = colnames(.)[3]) %>%\n",
                "  dplyr::mutate(corpus = stringr::str_replace_all(corpus, \".*data/(.*?)/.*\", \"\\\\1\"),\n",
                "                file = stringr::str_replace_all(file, \".*Raw/(.*?)-raw.*\", \"\\\\1\"),\n",
                "                speaker = stringr::str_remove_all(text, \":.*\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"\\\\W.*\\\\W\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"[^[:alpha:]]\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"[a-z]\"),\n",
                "                textclean = stringr::str_remove_all(text, \"<.*?>\"),\n",
                "                textclean = stringr::str_remove_all(textclean, \"(.*?)\"),\n",
                "                textclean = stringr::str_remove(textclean, \"[0-9]{0,} {0,}[A-Z]{1,}:\"),\n",
                "                textclean = stringr::str_remove_all(textclean, \"[^[:alpha:]â€™ ]\"),\n",
                "                textclean = stringr::str_squish(textclean))\n",
                "rownames(gridf) <- NULL\n",
                "# inspect\n",
                "knitr::kable(head(gridf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic03.JPG?raw=true)\n",
                "\n",
                "### Load MON\n",
                "\n",
                "We continue with the content of the files of the *Monash corpus* (mon)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vmon <- sapply(fmon, function(x){\n",
                "  x <- readLines(x, encoding = \"UTF-8\")\n",
                "  x <- x[x != \"\"]\n",
                "  x <- paste0(x, collapse = \"qwertz\") %>%\n",
                "  stringr::str_remove_all(\"qwertz    \") %>%\n",
                "  stringr::str_split(\"qwertz\") %>%\n",
                "  unlist() %>%\n",
                "  stringr::str_squish()\n",
                "  })\n",
                "# unlist\n",
                "montext <- unlist(vmon)\n",
                "# collapse into df\n",
                "mondf <- data.frame(names(montext), names(montext), montext) %>%\n",
                "  dplyr::rename(corpus = colnames(.)[1],\n",
                "                file = colnames(.)[2],\n",
                "                text = colnames(.)[3]) %>%\n",
                "  dplyr::mutate(corpus = stringr::str_replace_all(corpus, \".*data/(.*?)/.*\", \"\\\\1\"),\n",
                "                file = stringr::str_replace_all(file, \".*Text/(.*?).txt\", \"\\\\1\"),\n",
                "                speaker = paste0(\"NA\"),\n",
                "                textclean = stringr::str_squish(text))\n",
                "rownames(mondf) <- NULL\n",
                "# inspect\n",
                "knitr::kable(head(mondf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic04.JPG?raw=true)\n",
                "\n",
                "### Load LAT\n",
                "\n",
                "We continue with the content of the files of the *The La Trobe Corpus of Spoken Australian English* (lat)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vlat <- sapply(flat, function(x){\n",
                "  x <- readLines(x, encoding = \"UTF-8\")\n",
                "  x <- x[x != \"\"]\n",
                "  })\n",
                "lattext <- unlist(vlat)\n",
                "# collapse into df\n",
                "latdf <- data.frame(names(lattext), names(lattext),lattext) %>%\n",
                "  dplyr::rename(corpus = colnames(.)[1],\n",
                "                file = colnames(.)[2],\n",
                "                text = colnames(.)[3]) %>%\n",
                "  dplyr::mutate(corpus = stringr::str_replace_all(corpus, \".*data/(.*?)/.*\", \"\\\\1\"),\n",
                "                file = stringr::str_replace_all(file, \".*Raw/(.*?)-raw.*\", \"\\\\1\"),\n",
                "                speaker = stringr::str_remove_all(text, \":.*\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"\\\\W.*\\\\W\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"[^[:alpha:]]\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"[a-z]\"),\n",
                "                textclean = stringr::str_remove_all(text, \"^[A-Z]{1,}:{0,1}\"),\n",
                "                textclean = stringr::str_squish(textclean))\n",
                "rownames(latdf) <- NULL\n",
                "# inspect\n",
                "knitr::kable(head(latdf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic05.JPG?raw=true)\n",
                "\n",
                "## Collapse data into one table\n",
                "\n",
                "We now combine the corpora into a single data frame called *oz*.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "oz <- rbind(artdf, gridf, mondf, latdf)\n",
                "# inspect\n",
                "knitr::kable(head(oz))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic06.JPG?raw=true)\n",
                "\n",
                "## Extract UF-or\n",
                "\n",
                "In a next step, we extract utterances with utterance final *or*. We determine this by checking if a string (utterance) ends with the sequence *or* but we allow for another words to come after the or if it has up to three chacraters (e.g., \"... or uhm?\").\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor <- oz %>%\n",
                "  dplyr::mutate(ufor = ifelse(stringr::str_detect(textclean, \" or {0,}.{0,3}$\"), 1, 0)) %>%\n",
                "  dplyr::filter(ufor == 1)\n",
                "# inspect\n",
                "knitr::kable(head(ufor$textclean))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic07.JPG?raw=true)\n",
                "\n",
                "Next, we want to extract concordances (keywords-in-context) of potential hits (utterance-final *or*). The context should be two utterances preceding the utterance with utterance-final *or* and two utterances following the instance of utterance-final *or*.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inds = which(stringr::str_detect(oz$textclean, \" or {0,}.{0,3}$\"))\n",
                "# We use lapply() to get all rows for all indices, result is a list\n",
                "rows <- lapply(inds, function(x) (x-2):(x+2))\n",
                "# With unlist() you get all relevant rows\n",
                "ufors <- oz[unlist(rows),]\n",
                "# insepct\n",
                "knitr::kable(head(ufors, 10))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic08.JPG?raw=true)\n",
                "\n",
                "We now generate a table with the instances of utterance-final *or* and the preceding as well as subsequent utterances and save the data to out computer for the manual annotation of the functions of utterance-final *or*.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# label instances\n",
                "nhits <- sapply(rows, function(x){ length(x) })\n",
                "nints <- 1:length(rows)\n",
                "labs <- rep(paste0(\"instance \", nints), each = nhits)\n",
                "# label context\n",
                "contlabs <- rep(c(\"pre2\", \"pre1\", \"hit\", \"post1\", \"post2\"), length(rows))\n",
                "# add to kwics\n",
                "ufors <- ufors %>%\n",
                "  dplyr::mutate(hit = labs,\n",
                "                context = contlabs) %>%\n",
                "  dplyr::select(-speaker, -textclean) %>%\n",
                "  dplyr::relocate(corpus, file, hit, context, text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data frame now contains five lines for each instance: *pre2*, *pre1*, *hit*, *post1*, and *post2*. The instance of utterance-final *or* is shown in the row labeled as *hit*. The table below shows the first 10 lines of the data frame (i.e., 2 instances of utterance-final *or* plus two utterances before the instance, labelled *pre2* and *pre1*, and two utterances after the instance of utterance-final *or*, labelled *post1* and *post2*).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "knitr::kable(head(ufors, 10))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "![](https://github.com/MartinSchweinberger/IJCL_ReproducibilityInCorpusPragmatics/blob/main/images/pic09.JPG?raw=true)\n",
                "\n",
                "# Save data to disc for manual annotation\n",
                "\n",
                "We now save the data so that we can annotate and code the data manually in a spreadsheet software (MS Excel).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save\n",
                "write.xlsx(ufors, here::here(\"tables\", \"step1_ufor_complete.xlsx\"), sheetName = \"Sheet1\", \n",
                "           colNames = TRUE, \n",
                "           rowNames = TRUE, \n",
                "           append = FALSE)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 2: Manual annotation \n",
                "\n",
                "This section details the annotation scheme used to manually annotate the instances of UF-or in a spreadsheet software (MS Excel).\n",
                "\n",
                "Manual annotation focused on: \n",
                "\n",
                "1. action format (Question or Assertion)  \n",
                "2. question type (polar, alternative, Q-word), and   \n",
                "3. identification of false positives (FP)\n",
                "\n",
                "**UF-or data annotation scheme**\n",
                "\n",
                "The annotation scheme used to code individual instances of utterance-final *or* is provided below. Each instance was inspected and annotated with regard to the categories shown below.\n",
                "\n",
                "\n",
                "Action format | Question type | Response polarity | Response elaboration | Response alignment\n",
                "|------------------------------------------------|---------------------------------------------|------------------------------------|-----------------------------------------|-------------------------------------------|----------------------------------------|\n",
                "Question [Q]| Information-seeking question [Q]| Yes [Y]| Explicit (yes/no, direct repeat) [E]| Type-conforming (yes/no; A or B) [TC]\n",
                "Assertion [A]| Polar question [P]| No [N]| Not explicit [NE]| Non-type-conforming [NTC]\n",
                "| | Alternative question [A]| Yes-No [Y-N]| | \n",
                "| | False positive (i.e.Â not a question) [FP]| B-answer [B]| | \n",
                "| | | No Answer [NoA]| | \n",
                "\n",
                "\n",
                "\n",
                "# INTERACTIVE CODE BELOW\n",
                "\n",
                ">\n",
                "> **THE CODE CHUNKS BELOW ARE INTERACTIVE (EXECUTABLE)** WHICH ALLOWS YOU TO INSPECT THE DATA AND PROBE IT IN GREATER DETAIL.\n",
                ">\n",
                "\n",
                "# Data Exploration and Analysis\n",
                "\n",
                "We now load the manually annotated data and check what the data looks like.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2 <- openxlsx::read.xlsx(here::here(\"tables\", \"step2_ufors_qa_annotated.xlsx\"), sheet = 1)\n",
                "# inspect\n",
                "ufor_step2 %>%\n",
                "  dplyr::filter(corpus == \"The La Trobe Corpus of Spoken Australian English\") %>%\n",
                "  # show first 10 rows\n",
                "  head(10) %>%\n",
                "  # show results as a table\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The table has the following columns:\n",
                "\n",
                "*  X1:  an identifier value allowing us to unambiguously identifying every row in the data.  \n",
                "* corpus: the name of the corpus  in which the potential instance occurred\n",
                "* file: the file in which the potential instance occurred\n",
                "* hit: the number of the potential instance  \n",
                "* context: specification of whether the text shows previous utterances (pre2 and pre1), the instance itself (hit), or subsequent utterances (post1 and post2)  \n",
                "* text: the utterance preceding, containing, or following a potential instance of UF-or  \n",
                "* action.format: Question or Assertion \n",
                "* question.type: Polar, Alternative, Q-word  \n",
                "\n",
                "\n",
                "Most of the cells are empty and do not contain any annotation information (these are all cells containing *NA* which stands for *not applicable*).\n",
                "\n",
                "We continue by cleaning the data, for example, by replacing `NA` and renaming columns and variable levels to be easier to understand \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean <- ufor_step2 %>%\n",
                "  dplyr::group_by(hit) %>%\n",
                "  tidyr::fill(action.format, .direction = \"updown\") %>%\n",
                "  tidyr::fill(question.type, .direction = \"updown\") %>%\n",
                "  # rename\n",
                "  dplyr::rename(`Action Format` = action.format,\n",
                "                `Question Type` = question.type) %>%\n",
                "  # renaming levels\n",
                "  dplyr::mutate(`Action Format` = factor(`Action Format`, \n",
                "                                       levels = c(\"Q\", \"A\"), \n",
                "                                       labels = c(\"Question (interrogative)\", \"Assertion (declarative)\")),\n",
                "                `Question Type`  = factor(`Question Type`, \n",
                "                                       levels = c(\"P\", \"A\", \"Q\", \"FP\"), \n",
                "                                       labels = c(\"Polar question\", \"Alternative question\", \"Q-word question\", \"False positive\"))) %>%\n",
                "  # remove grouping\n",
                "  dplyr::ungroup()\n",
                "# inspect\n",
                "head(ufor_step2_clean, 5)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now create a first overview table showing how many instances there are per Action Format.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "    dplyr::filter(context == \"hit\") %>%\n",
                "  dplyr::mutate(`Question Type` = ifelse(`Question Type` == \"False positive\", \"False positive\", \"N\")) %>%\n",
                "  dplyr::group_by(`Action Format`,`Question Type`) %>%\n",
                "  dplyr::summarise(N = n()) %>%\n",
                "  tidyr::spread(`Question Type`, N) %>%\n",
                "  dplyr::mutate(N = N + `False positive`) %>%\n",
                "  dplyr::relocate(`False positive`, .after = N) %>%\n",
                "  replace(is.na(.), 0) \n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Candidate UF-or information seeking questions (N=63: 73-10)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  dplyr::filter(`Question Type` != \"False positive\") %>%\n",
                "  dplyr::group_by(`Question Type`) %>%\n",
                "  dplyr::summarise(N = n()) %>%\n",
                "  dplyr::add_row(`Question Type` = \"Total\", \n",
                "                 N = sum(.$N))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## False positives\n",
                "\n",
                "All false positives combined.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  dplyr::filter(`Question Type` == \"False positive\") %>%\n",
                "  dplyr::group_by(`Question Type`) %>%\n",
                "  dplyr::summarise(N = n())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**1. Assertions (N=25)**  \n",
                "\n",
                "As we were interested in UF-or questions, assertions were by definition false positives (although an interesting phenomenon in its own right). \n",
                "\n",
                "For example *Suggestion/advice marked with UF-or* (N=1)\n",
                "\n",
                "ART: COME3 (instance 13):\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 13\") %>%\n",
                "  dplyr::filter(context == \"hit\"| context == \"post1\") %>%\n",
                "  dplyr::mutate(text = stringr::str_remove_all(text, \".*>. \")) %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**2. Interrogatives (N=10)**  \n",
                "\n",
                "a. FP due to question being request for permission rather than request for information (N=1)\n",
                "\n",
                "ART: COME3 (instance 16)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 16\") %>%\n",
                "  dplyr::filter(context != \"post2\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "b. FP due to instance being utterance-medial rather than utterance-final (N=3)\n",
                "\n",
                "MCE: MECG1M1 (instance 54)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 54\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "LTCE: Beth & Daniel (instance 82)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 82\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "MCE: MESJ3F1 (instance 73):\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 73\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "c. FP created through script (N=6), i.e.: \n",
                "\n",
                "* *or not* (instance 42, 76, 92)  \n",
                "* *or no* (instance 78)  \n",
                "* *or so* (instance 22)  \n",
                "* *or two* (instance 41)\n",
                "\n",
                "***or not***\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(`Question Type` == \"False positive\",\n",
                "                context == \"hit\") %>%\n",
                "  dplyr::filter(hit == \"instance 42\" | hit == \"instance 76\" | hit == \"instance 92\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***or no***\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(`Question Type` == \"False positive\",\n",
                "                context == \"hit\") %>%\n",
                "  dplyr::filter(hit == \"instance 78\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***or so***\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(`Question Type` == \"False positive\",\n",
                "                context == \"hit\") %>%\n",
                "  dplyr::filter(hit == \"instance 22\") %>%\n",
                "  dplyr::mutate(text = stringr::str_remove_all(text, \".*away. \")) %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "***or two***\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(`Question Type` == \"False positive\",\n",
                "                context == \"hit\") %>%\n",
                "  dplyr::filter(hit == \"instance 41\") %>%\n",
                "  dplyr::mutate(text = stringr::str_remove_all(text, \".* 19 \")) %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**False negative (N=1)**\n",
                "\n",
                "\n",
                "(identified by Haugh 2011 in GCSAusE, but not extracted through script)\n",
                "(GCSAusE011)\n",
                "\n",
                "T: =so is it? (.) is it easy? o:r [like what]  \n",
                "B:                                               [ itâ€™s   ha:  ]rd,\n",
                "\n",
                "\n",
                "# Step 3: Manual annotation \n",
                "\n",
                "This section focuses on polar interrogatives.\n",
                "\n",
                "Responses to UF-or polar interrogatives were manually annotated by analyst (bottom-up [data-driven] and top-down [previous studies] annotation schema) (n=55)\n",
                "\n",
                "Manual annotation focused on: \n",
                "\n",
                "1. response **polarity** (confirming [Y], disconfirming [N], (dis)confirming [Y-N], non-answers [NA])  \n",
                "2. response **alignment** (type-conforming [TC], non-type-conforming [NTC])  \n",
                "3. response **elaboration** (elaboration [E], no elaboration [NE])  \n",
                "\n",
                "We now load the manually annotated data and check what the data looks like.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3 <- openxlsx::read.xlsx(here::here(\"tables\", \"step3_ufors_qp_annotated.xlsx\"), sheet = 1)\n",
                "# inspect\n",
                "ufor_step3 %>%\n",
                "  dplyr::filter(corpus == \"The La Trobe Corpus of Spoken Australian English\") %>%\n",
                "  # show first 10 rows\n",
                "  head(10) %>%\n",
                "  # show results as a table\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The table has the following columns:\n",
                "\n",
                "*  X1:  an identifier value allowing us to unambiguously identifying every row in the data.    \n",
                "* corpus: the name of the corpus  in which the potential instance occurred  \n",
                "* file: the file in which the potential instance occurred  \n",
                "* hit: the number of the potential instance  \n",
                "* context: specification of whether the text shows previous utterances (pre2 and pre1), the instance itself (hit), or subsequent utterances (post1 and post2)  \n",
                "* text: the utterance preceding, containing, or following a potential instance of UF-or  \n",
                "* action.format: Question or Assertion  \n",
                "* question.type: Polar, Alternative, Q-word  \n",
                "* response.polarity: Polarity of the response (post1) -confirming [Y], disconfirming [N], (dis)confirming [Y-N], non-answers [NA]   \n",
                "* response.elaboration: Elaboration of the response (post1) - elaboration [E], no elaboration [NE]  \n",
                "* response.alignment: Alignment of the response (post1) - type-conforming [TC], non-type-conforming [NTC]   \n",
                "\n",
                "\n",
                "Most of the cells are empty and do not contain any annotation information (these are all cells containing *NA* which stands for *not applicable*).\n",
                "\n",
                "We continue by cleaning the data, for example, by replacing `NA` and renaming columns and variable levels to be easier to understand \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean <- ufor_step3 %>%\n",
                "  dplyr::mutate(question.type = str_squish(question.type)) %>%\n",
                "  dplyr::group_by(hit) %>%\n",
                "  tidyr::fill(action.format, .direction = \"updown\") %>%\n",
                "  tidyr::fill(question.type, .direction = \"updown\") %>%\n",
                "  tidyr::fill(response.polarity, .direction = \"updown\") %>%\n",
                "  tidyr::fill(response.alignment, .direction = \"updown\") %>%\n",
                "  tidyr::fill(response.elaboration, .direction = \"updown\") %>%\n",
                "  # rename\n",
                "  dplyr::rename(`Action Format` = action.format,\n",
                "                `Question Type` = question.type,\n",
                "                `Response Polarity` = response.polarity,\n",
                "                `Response Alignment` = response.alignment,\n",
                "                `Response Elaboration` = response.elaboration) %>%\n",
                "  # renaming levels\n",
                "  dplyr::mutate(`Action Format` = factor(`Action Format`, \n",
                "                                       levels = c(\"Q\", \"A\"), \n",
                "                                       labels = c(\"Question (interrogative)\", \"Assertion (declarative)\")),\n",
                "                `Question Type`  = factor(`Question Type`, \n",
                "                                       levels = c(\"P\", \"A\", \"Q\", \"FP\"), \n",
                "                                       labels = c(\"Polar question\", \"Alternative question\", \"Q-word question\", \"False positive\")),\n",
                "                `Response Polarity`  = factor(`Response Polarity`, \n",
                "                                       levels = c(\"Y\", \"N\", \"YN\", \"B\", \"NoA\"), \n",
                "                                       labels = c(\"Confirming [Y]\", \"Disconfirming [N]\", \"(Dis)confirming [Y-N]\", \"B-answer [B]\", \"Non-answers [NA]\")),\n",
                "                `Response Alignment`  = factor(`Response Alignment`, \n",
                "                                       levels = c(\"TC\", \"NTC\"), \n",
                "                                       labels = c(\"Type-Conforming [TC]\", \"Non-Type-Conforming [NTC]\")),\n",
                "                `Response Elaboration`  = factor(`Response Elaboration`, \n",
                "                                       levels = c(\"E\", \"NE\"), \n",
                "                                       labels = c(\"Elaboration [E]\", \"No elaboration [NE]\"))) %>%\n",
                "  # remove grouping\n",
                "  dplyr::ungroup()\n",
                "# inspect\n",
                "head(ufor_step3_clean, 5)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now generate an overview tables.\n",
                "\n",
                "## Response Polarity\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "    dplyr::filter(context == \"hit\") %>%\n",
                "  dplyr::mutate(`Response Polarity` = dplyr::case_when(`Response Polarity` == \"B-answer [B]\" ~ \"Non-polar\",\n",
                "                                                       `Response Polarity` == \"Non-answers [NA]\" ~ \"Non-polar\", \n",
                "                                                       T ~ `Response Polarity`)) %>%\n",
                "  dplyr::group_by(`Response Polarity`) %>%\n",
                "  dplyr::summarise(N = n()) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Total = sum(N)) %>%\n",
                "  dplyr::rowwise() %>%\n",
                "  dplyr::mutate(Percent = round(N/Total*100, 1)) %>%\n",
                "  dplyr::select(-Total) %>%\n",
                "  dplyr::add_row(`Response Polarity` = \"Total\",\n",
                "                 N = sum(.$N),\n",
                "                 Percent = sum(.$Percent)) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "    dplyr::filter(context == \"hit\") %>%\n",
                "  dplyr::mutate(`Response Polarity` = dplyr::case_when(`Response Polarity` == \"B-answer [B]\" ~ \"B-answer [B]\",\n",
                "                                                       `Response Polarity` == \"Non-answers [NA]\" ~ \"Non-answers [NA]\",\n",
                "                                                       T ~ \"Polar\")) %>%\n",
                "  dplyr::group_by(`Response Polarity`) %>%\n",
                "  dplyr::summarise(N = n()) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Total = sum(N)) %>%\n",
                "  dplyr::rowwise() %>%\n",
                "  dplyr::mutate(Percent = round(N/Total*100, 1)) %>%\n",
                "  dplyr::select(-Total) %>%\n",
                "  dplyr::add_row(`Response Polarity` = \"Total\",\n",
                "                 N = sum(.$N),\n",
                "                 Percent = sum(.$Percent)) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "    dplyr::filter(context == \"hit\") %>%\n",
                "  dplyr::mutate(`Response Polarity` = dplyr::case_when(`Response Polarity` == \"B-answer [B]\" ~ \"Non-polar\",\n",
                "                                                       `Response Polarity` == \"Non-answers [NA]\" ~ \"Non-polar\",\n",
                "                                                       T ~ \"Polar\")) %>%\n",
                "  dplyr::group_by(`Response Polarity`) %>%\n",
                "  dplyr::summarise(N = n()) %>%\n",
                "  dplyr::arrange(-N) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Total = sum(N)) %>%\n",
                "  dplyr::rowwise() %>%\n",
                "  dplyr::mutate(Percent = round(N/Total*100, 1)) %>%\n",
                "  dplyr::select(-Total) %>%\n",
                "  dplyr::add_row(`Response Polarity` = \"Total\",\n",
                "                 N = sum(.$N),\n",
                "                 Percent = sum(.$Percent)) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Elaboration\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "    dplyr::filter(context == \"hit\") %>%\n",
                "  dplyr::mutate(`Response Polarity` = dplyr::case_when(`Response Polarity` == \"B-answer [B]\" ~ \"Non-polar\",\n",
                "                                                       `Response Polarity` == \"Non-answers [NA]\" ~ \"Non-polar\",\n",
                "                                                       T ~ \"Polar\")) %>%\n",
                "  dplyr::filter(`Response Polarity` == \"Polar\") %>%\n",
                "  dplyr::group_by(`Response Elaboration`) %>%\n",
                "  dplyr::summarise(N = n()) %>%\n",
                "  dplyr::arrange(-N) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Total = sum(N)) %>%\n",
                "  dplyr::rowwise() %>%\n",
                "  dplyr::mutate(Percent = round(N/Total*100, 1)) %>%\n",
                "  dplyr::select(-Total) %>%\n",
                "  dplyr::add_row(`Response Elaboration` = \"Total\",\n",
                "                 N = sum(.$N),\n",
                "                 Percent = sum(.$Percent)) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Response Alignment\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  group_by(`Response Alignment`) %>% \n",
                "  dplyr::summarise(N = n()) %>%\n",
                "  dplyr::arrange(-N) %>%\n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Total = sum(N)) %>%\n",
                "  dplyr::rowwise() %>%\n",
                "  dplyr::mutate(Percent = round(N/Total*100, 1)) %>%\n",
                "  dplyr::select(-Total) %>%\n",
                "  dplyr::add_row(`Response Alignment` = \"Total\",\n",
                "                 N = sum(.$N),\n",
                "                 Percent = sum(.$Percent)) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "  dplyr::filter(context == \"hit\",\n",
                "                `Response Alignment` == \"Type-Conforming [TC]\") %>%\n",
                "  dplyr::mutate(`Response Polarity` = dplyr::case_when(`Response Polarity` == \"Confirming [Y]\" ~ \"Confirming [Y]\",\n",
                "                                                       `Response Polarity` == \"Disconfirming [N]\" ~ \"Disconfirming [N]\",\n",
                "                                                       TRUE ~ \"other\")) %>% \n",
                "  group_by(`Response Alignment`, `Response Polarity`) %>% \n",
                "  dplyr::summarise(Frequency = n()) %>%\n",
                "  dplyr::arrange(-Frequency) %>%\n",
                "  tidyr::spread(`Response Alignment`, Frequency) %>%\n",
                "  replace(is.na(.), 0) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "  dplyr::filter(context == \"hit\",\n",
                "                `Response Alignment` == \"Non-Type-Conforming [NTC]\") %>%\n",
                "  dplyr::mutate(`Response Polarity` = dplyr::case_when(`Response Polarity` == \"Confirming [Y]\" ~ \"Confirming [Y]\",\n",
                "                                                       `Response Polarity` == \"Disconfirming [N]\" ~ \"Disconfirming [N]\",\n",
                "                                                       `Response Polarity` == \"(Dis)confirming [Y-N]\" ~ \"(Dis)confirming [Y-N]\",\n",
                "                                                       TRUE ~ \"Non-polar\")) %>% \n",
                "  group_by(`Response Alignment`, `Response Polarity`) %>% \n",
                "  dplyr::summarise(Frequency = n()) %>%\n",
                "  dplyr::arrange(-Frequency) %>%\n",
                "  tidyr::spread(`Response Alignment`, Frequency) %>%\n",
                "  replace(is.na(.), 0) %>% \n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Total = sum(`Non-Type-Conforming [NTC]`)) %>%\n",
                "  dplyr::rowwise() %>%\n",
                "  dplyr::mutate(Percent = round(`Non-Type-Conforming [NTC]`/Total*100, 1)) %>%\n",
                "  dplyr::select(-Total) %>%\n",
                "  dplyr::add_row(`Response Polarity` = \"Total\",\n",
                "                 `Non-Type-Conforming [NTC]` = sum(.$`Non-Type-Conforming [NTC]`),\n",
                "                 Percent = sum(.$Percent)) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "  dplyr::filter(context == \"hit\",\n",
                "                `Response Alignment` == \"Non-Type-Conforming [NTC]\") %>%\n",
                "  dplyr::mutate(`Response Polarity` = dplyr::case_when(`Response Polarity` == \"Confirming [Y]\" ~ \"Polar\",\n",
                "                                                       `Response Polarity` == \"Disconfirming [N]\" ~ \"Polar\",\n",
                "                                                       `Response Polarity` == \"(Dis)confirming [Y-N]\" ~ \"Polar\",\n",
                "                                                       TRUE ~ \"Non-polar\")) %>% \n",
                "  group_by(`Response Alignment`, `Response Polarity`) %>% \n",
                "  dplyr::summarise(Frequency = n()) %>%\n",
                "  dplyr::arrange(-Frequency) %>%\n",
                "  tidyr::spread(`Response Alignment`, Frequency) %>%\n",
                "  replace(is.na(.), 0) %>% \n",
                "  dplyr::ungroup() %>%\n",
                "  dplyr::mutate(Total = sum(`Non-Type-Conforming [NTC]`)) %>%\n",
                "  dplyr::rowwise() %>%\n",
                "  dplyr::mutate(Percent = round(`Non-Type-Conforming [NTC]`/Total*100, 1)) %>%\n",
                "  dplyr::select(-Total) %>%\n",
                "  dplyr::add_row(`Response Polarity` = \"Total\",\n",
                "                 `Non-Type-Conforming [NTC]` = sum(.$`Non-Type-Conforming [NTC]`),\n",
                "                 Percent = sum(.$Percent)) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Step 4: Computational-interpretive analysis \n",
                "\n",
                "Computationally analysed responses to UF-or information-seeking polar questions [Q-P] using pivot tables and manual close-reading (N=55)\n",
                "\n",
                "1. UF-or information seeking questions are invariably responded as polar questions  \n",
                "2. UF-or makes elaboration a relevant next   \n",
                "\n",
                "## 1. UF-or information seeking questions are invariably responded as polar questions \n",
                "\n",
                "Hypothesis: UF-or information-seeking questions are invariably responded to as polar questions (i.e. p or not?) rather than alternative questions (i.e. p or q?) (cf. Haugh 2011)\n",
                "\n",
                "**a. Distributional evidence** \n",
                "\n",
                "48/55 responses are confirming/disconfirming/(dis)confirming (i.e. respond to as polar Q) (87.3%)\n",
                "\n",
                "2/55 responses are q responses (i.e. respond to as alternative Q) (3.6%)\n",
                "\n",
                "4/55 responses are non-answer responses (i.e. equivocal as to whether treating it as polar Q) (7.3%)\n",
                "\n",
                "**b. Interpretive evidence**\n",
                "\n",
                "*Alternative responses and non-answers are occasioned by teasing or repair (N=6)*.\n",
                "\n",
                "Alternative answers are used as vehicles for teasing or repair (N=2):\n",
                "\n",
                "1. (MCE: MEBH2FB, instance 50)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 50\") %>%\n",
                "  dplyr::filter(context != \"pre2\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> q response to deliver counter-tease\n",
                "> information-seeking question as vehicle for teasing challenge\n",
                "\n",
                "2. (MCE: MECG2M1, instance 61)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 61\") %>%\n",
                "  dplyr::filter(context != \"pre2\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> q response (confirming)\n",
                "> post-first insert expansion of prior information-seeking (Q-word) question\n",
                "\n",
                "*Non-answer responses are used as vehicles for teases, responses to teases or repair (N=4)*\n",
                "\n",
                "1. (ART: NAT2, instance 27)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 27\") %>%\n",
                "  dplyr::filter(context != \"pre2\",\n",
                "                context != \"pre1\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> non-answer response\n",
                "> teasing Q-producer\n",
                "> Q-producer pursues response to her question\n",
                "\n",
                "(2) (ART: ABCE2, instance 3)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 3\") %>%\n",
                "  dplyr::filter(context != \"pre2\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> non-answer response in response to tease\n",
                "> stand-alone â€˜orâ€™ to jokingly bait recipient\n",
                "\n",
                "(3) ART: COMNE1 (instance 18)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 18\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> non-answer response\n",
                "> information-seeking question as vehicle for tease\n",
                "\n",
                "(4) ART: COME4 (instance 14)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 14\") %>%\n",
                "  dplyr::filter(context != \"pre2\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> non-answer response\n",
                "> repair of terms of prior Q\n",
                "\n",
                "## 2. UF-or makes elaboration a relevant next \n",
                "\n",
                "UF-or makes elaboration a relevant next (cf. Drake 2015)\n",
                "\n",
                "(n=49) NB. Alternative and non-answer responses (n=6) removed from count of (non)elaboration\n",
                "\n",
                "**a. Distributional evidence**\n",
                "\n",
                "(Dis)confirmation only (N=11) (22.4%)\n",
                "\tconfirmation only (N=7)\n",
                "\tdisconfirmation only (N=4)\n",
                "\t\n",
                "(Dis)confirmation + elaboration (N=38) (77.6%)\n",
                "\tconfirmation + elaboration (N=18)\n",
                "\t(dis)confirmation + elaboration (N=4)\n",
                "\tdisconfirmation + elaboration (N=16)\n",
                "\n",
                "**b. Interpretive evidence: Deviant cases**\n",
                "\n",
                "> non-production of elaboration treated as accountable absence\n",
                "\n",
                "MCE: MEBH1MB (instance 47) [deviant case]\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 47\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> treats minimal confirmation as requiring elaboration\n",
                "\n",
                "**c. Interpretive evidence: Borderline cases**\n",
                "\n",
                "Bare confirmation/disconfirmation functions as \"go ahead\" response\n",
                "\n",
                "ART: COMNE3 (instance 21)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 21\") %>%\n",
                "  dplyr::filter(context != \"pre2\",\n",
                "                context != \"pre1\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "MCE: MEBH2FB (instance 49)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 49\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "MCE: MESJ3F1 (instance 72)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 72\") %>%\n",
                "  dplyr::filter(context != \"pre2\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Bare confirmation occasioned by noticing of matter external to ongoing sequence\n",
                "\n",
                "GCS: AusE32 (instance 44)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 44\") %>%\n",
                "  dplyr::filter(context != \"pre2\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "96  J: \tSo yeah:: ya gonna drop into the u:m (1.8) you gonna drop into \n",
                "97 \tthe: tent embassy:: or:? \n",
                "98 \t(1.4) \n",
                "99  S: \tYeah man \n",
                "100 \t(.)\n",
                "101 J:\tCheck â†‘that outâ†‘\n",
                "\n",
                "Bare disconfirmation for emphatic (repeated) rejection\n",
                "\n",
                "> emphatic rejection treats question as inapposite\n",
                "\n",
                "ART: COMNE4 (instance 23)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 23\") %>%\n",
                "  dplyr::filter(context != \"pre2\",\n",
                "                context != \"pre1\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "ART: ABCE1 (instance 2)\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "#ufor_step2_clean$hit[str_detect(ufor_step2_clean$text, \"hear a little bit\")]\n",
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 2\") %>%\n",
                "  dplyr::filter(context != \"post2\") %>%\n",
                "  dplyr::select(text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Further exploration of the data\n",
                "\n",
                "This section provides pre-written code snippets that allow researchers to further explore the data.\n",
                "\n",
                "## Inspecting specific instances\n",
                "\n",
                "There are overall 98 instances of potential instances of UF-or. You can access any of these (including the respective coding) if you modify the number following the sequence `\"instance \"` in the code below.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(hit == \"instance 2\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "If you want to inspect the instances and coding in the data set loaded for step 3, you simply need to change `ufor_step2_clean` to `ufor_step3_clean`.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step3_clean %>%\n",
                "  dplyr::filter(hit == \"instance 2\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Tabulation can be done by filtering the row containing the instance of UF-or and then grouping and summarizing based on what you want to tabulate.\n",
                "\n",
                "For example, if you want to inspect the number of false positives among question types, you could use the command below.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  group_by(`Question Type`) %>%\n",
                "  summarise(Frequency = n())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Or, if you want to inspect the number of  question types across , you could use the command below.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_step2_clean %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  group_by(`Question Type`, `Action Format`) %>%\n",
                "  summarise(Frequency = n())\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Outro\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sessionInfo()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
