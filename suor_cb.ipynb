{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Preparation\n",
                "\n",
                "In a first step, we load or activate the packages.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "library(tidyverse)\n",
                "library(quanteda)\n",
                "library(here)\n",
                "library(openxlsx)\n",
                "library(flextable)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Loading and Processing\n",
                "\n",
                "For this analysis, we will use dta from the following corpora:\n",
                "\n",
                "\n",
                "* [Australian Radio Talkback](https://www.ausnc.org.au/corpora/art)\n",
                "\n",
                "* [Griffith Corpus of Spoken Australian English](https://www.ausnc.org.au/corpora/gcsause)\n",
                "\n",
                "* [Monash corpus](https://www.ausnc.org.au/corpora/monash)\n",
                "\n",
                "* [The La Trobe Corpus of Spoken Australian English](https://www.ausnc.org.au/corpora/latrobecsause)\n",
                "\n",
                "## Loading data\n",
                "\n",
                "The corpora were downloaded and stored in a directory (folder) called `data`. To load the data, we define the paths to the files containing the transcripts (which are located in the `data` folder in the specific sub-directories for the corpora).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "fart <- list.files(here::here(\"data\", \"Australian Talkback Radio/files/Raw\"), \n",
                "                        pattern = \".txt\", full.names = T)\n",
                "fgri <- list.files(here::here(\"data\", \"Griffith Corpus of Spoken Australian English/files/Raw\"), \n",
                "                        pattern = \".txt\", full.names = T)\n",
                "fmon <- list.files(here::here(\"data\", \"Monash/files/Text\"), \n",
                "                        pattern = \".txt\", full.names = T)\n",
                "flat <- list.files(here::here(\"data\", \"The La Trobe Corpus of Spoken Australian English/files/Raw\"), \n",
                "                        pattern = \".txt\", full.names = T)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now check if we have the paths to the data by inspecting the first six paths of files in the *Australian Radio Talkback* corpus.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "flextable(head(fart))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now proceed by loading and processing (cleaning) the data.\n",
                "\n",
                "### Load ART\n",
                "\n",
                "We start with the  content of the *Australian Radio Talkback* corpus (art).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# load raw content\n",
                "vart <- sapply(fart, function(x){\n",
                "  x <- readLines(x)\n",
                "  x <- x[x != \"\"]\n",
                "  })\n",
                "# unlist the object containign the corpus data\n",
                "arttext <- unlist(vart)\n",
                "# collapse into a data frame\n",
                "artdf <- data.frame(names(arttext), names(arttext),arttext) %>%\n",
                "  # rename columns\n",
                "  dplyr::rename(corpus = colnames(.)[1],\n",
                "                file = colnames(.)[2],\n",
                "                text = colnames(.)[3]) %>%\n",
                "  # create new columns containing corpus, file, and speaker information as well as a column with clean content\n",
                "  dplyr::mutate(\n",
                "    # extract corpus name\n",
                "    corpus = stringr::str_replace_all(corpus, \".*data/(.*?)/.*\", \"\\\\1\"),\n",
                "    # extract file name\n",
                "    file = stringr::str_replace_all(file, \".*Raw/(.*?)-raw.*\", \"\\\\1\"),\n",
                "    # extract speaker\n",
                "    speaker = stringr::str_replace_all(text, \"\\\\[(.*?)\\\\].*\", \"\\\\1\"),\n",
                "    # extract clean transcript\n",
                "    textclean = stringr::str_remove_all(text, \".*?\\\\]\"),\n",
                "    # remove superfluous white spaces\n",
                "    textclean = stringr::str_squish(textclean))\n",
                "# remove row names\n",
                "rownames(artdf) <- NULL\n",
                "# inspect\n",
                "flextable(head(artdf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load GRI\n",
                "\n",
                "We continue with the content of the files of the *Griffith Corpus of Spoken Australian English* (gri).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vgri <- sapply(fgri, function(x){\n",
                "  x <- readLines(x, encoding = \"UTF-8\")\n",
                "  x <- x[x != \"\"]\n",
                "  x <- x[!stringr::str_detect(x, \"\\\\|.*\\\\|\")]\n",
                "  x <- paste0(x, collapse = \" \")\n",
                "  x <- stringr::str_split(stringr::str_replace_all(x, \"( [A-Z]:)\", \"qwertz\\\\1\"), \"qwertz\")\n",
                "  x <- unlist(x)\n",
                "  x <- stringr::str_squish(x)\n",
                "})\n",
                "gritext <- unlist(vgri)\n",
                "# collapse into df\n",
                "gridf <- data.frame(names(gritext), names(gritext),gritext) %>%\n",
                "  dplyr::rename(corpus = colnames(.)[1],\n",
                "                file = colnames(.)[2],\n",
                "                text = colnames(.)[3]) %>%\n",
                "  dplyr::mutate(corpus = stringr::str_replace_all(corpus, \".*data/(.*?)/.*\", \"\\\\1\"),\n",
                "                file = stringr::str_replace_all(file, \".*Raw/(.*?)-raw.*\", \"\\\\1\"),\n",
                "                speaker = stringr::str_remove_all(text, \":.*\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"\\\\W.*\\\\W\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"[^[:alpha:]]\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"[a-z]\"),\n",
                "                textclean = stringr::str_remove_all(text, \"<.*?>\"),\n",
                "                textclean = stringr::str_remove_all(textclean, \"(.*?)\"),\n",
                "                textclean = stringr::str_remove(textclean, \"[0-9]{0,} {0,}[A-Z]{1,}:\"),\n",
                "                textclean = stringr::str_remove_all(textclean, \"[^[:alpha:]â€™ ]\"),\n",
                "                textclean = stringr::str_squish(textclean))\n",
                "rownames(gridf) <- NULL\n",
                "# inspect\n",
                "knitr::kable(head(gridf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load MON\n",
                "\n",
                "We continue with the content of the files of the *Monash corpus* (mon)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vmon <- sapply(fmon, function(x){\n",
                "  x <- readLines(x, encoding = \"UTF-8\")\n",
                "  x <- x[x != \"\"]\n",
                "  x <- paste0(x, collapse = \"qwertz\") %>%\n",
                "  stringr::str_remove_all(\"qwertz    \") %>%\n",
                "  stringr::str_split(\"qwertz\") %>%\n",
                "  unlist() %>%\n",
                "  stringr::str_squish()\n",
                "  })\n",
                "# unlist\n",
                "montext <- unlist(vmon)\n",
                "# collapse into df\n",
                "mondf <- data.frame(names(montext), names(montext), montext) %>%\n",
                "  dplyr::rename(corpus = colnames(.)[1],\n",
                "                file = colnames(.)[2],\n",
                "                text = colnames(.)[3]) %>%\n",
                "  dplyr::mutate(corpus = stringr::str_replace_all(corpus, \".*data/(.*?)/.*\", \"\\\\1\"),\n",
                "                file = stringr::str_replace_all(file, \".*Text/(.*?).txt\", \"\\\\1\"),\n",
                "                speaker = paste0(\"NA\"),\n",
                "                textclean = stringr::str_squish(text))\n",
                "rownames(mondf) <- NULL\n",
                "# inspect\n",
                "knitr::kable(head(mondf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Load LAT\n",
                "\n",
                "We continue with the content of the files of the *The La Trobe Corpus of Spoken Australian English* (lat)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "vlat <- sapply(flat, function(x){\n",
                "  x <- readLines(x, encoding = \"UTF-8\")\n",
                "  x <- x[x != \"\"]\n",
                "  })\n",
                "lattext <- unlist(vlat)\n",
                "# collapse into df\n",
                "latdf <- data.frame(names(lattext), names(lattext),lattext) %>%\n",
                "  dplyr::rename(corpus = colnames(.)[1],\n",
                "                file = colnames(.)[2],\n",
                "                text = colnames(.)[3]) %>%\n",
                "  dplyr::mutate(corpus = stringr::str_replace_all(corpus, \".*data/(.*?)/.*\", \"\\\\1\"),\n",
                "                file = stringr::str_replace_all(file, \".*Raw/(.*?)-raw.*\", \"\\\\1\"),\n",
                "                speaker = stringr::str_remove_all(text, \":.*\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"\\\\W.*\\\\W\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"[^[:alpha:]]\"),\n",
                "                speaker = stringr::str_remove_all(speaker, \"[a-z]\"),\n",
                "                textclean = stringr::str_remove_all(text, \"^[A-Z]{1,}:{0,1}\"),\n",
                "                textclean = stringr::str_squish(textclean))\n",
                "rownames(latdf) <- NULL\n",
                "# inspect\n",
                "knitr::kable(head(latdf))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Collapse data sources\n",
                "\n",
                "We now combine the corpora into a single data frame called *oz*.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "oz <- rbind(artdf, gridf, mondf, latdf)\n",
                "# inspect\n",
                "knitr::kable(head(oz))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Extract utterance-final or\n",
                "\n",
                "In a next step, we extract utterances with utterance final *or*. We determine this by checking if a string (utterance) ends with the sequence *or* but we allow for another words to come after the or if it has up to three chacraters (e.g., \"... or uhm?\").\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor <- oz %>%\n",
                "  dplyr::mutate(ufor = ifelse(stringr::str_detect(textclean, \" or {0,}.{0,3}$\"), 1, 0)) %>%\n",
                "  dplyr::filter(ufor == 1)\n",
                "# inspect\n",
                "knitr::kable(head(ufor$textclean))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In a next step,w e want to extract concordances (keywords-in-context) of potential hits (utterance-final *or*). The context should be two utterances preceding the utterance with utterance-final *or* and two utterances following the instance of utterance-final *or*.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "inds = which(stringr::str_detect(oz$textclean, \" or {0,}.{0,3}$\"))\n",
                "# We use lapply() to get all rows for all indices, result is a list\n",
                "rows <- lapply(inds, function(x) (x-2):(x+2))\n",
                "# With unlist() you get all relevant rows\n",
                "ufors <- oz[unlist(rows),]\n",
                "# insepct\n",
                "knitr::kable(head(ufors))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We now generate a table with the instances of utterance-final *or* and the preceding as well as subsequent utterances and save the data to out computer for the manual annotation of the functions of utterance-final *or*.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# label instances\n",
                "nhits <- sapply(rows, function(x){ length(x) })\n",
                "nints <- 1:length(rows)\n",
                "labs <- rep(paste0(\"instance \", nints), each = nhits)\n",
                "# label context\n",
                "contlabs <- rep(c(\"pre2\", \"pre1\", \"hit\", \"post1\", \"post2\"), length(rows))\n",
                "# add to kwics\n",
                "ufors <- ufors %>%\n",
                "  dplyr::mutate(hit = labs,\n",
                "                context = contlabs) %>%\n",
                "  dplyr::select(-speaker, -textclean) %>%\n",
                "  dplyr::relocate(corpus, file, hit, context, text)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "The data frame now contains five lines for each instance: *pre2*, *pre1*, *hit*, *post1*, and *post2*. The instance of utterance-final *or* is shown in the row labeled as *hit*.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "knitr::kable(head(ufors))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Save data to disc\n",
                "\n",
                "We now save the data so that we can annotate and code the data manually in a spreadsheet software (MS Excel).\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# save\n",
                "write.xlsx(ufors, here::here(\"tables\", \"ufors.xlsx\"), sheetName = \"Sheet1\", \n",
                "           col.names = TRUE, \n",
                "           row.names = TRUE, \n",
                "           append = FALSE)\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Manula Annotation (Coding)\n",
                "\n",
                "The data (ufors) were annotated manually in a spreadsheet software (MS Excel). \n",
                "\n",
                "## UF-or data annotation scheme\n",
                "\n",
                "The annotation scheme used to code individual instances of utterance-final *or* is provided below. Each instance was inspected and annotated with regard to the categories shown below.\n",
                "\n",
                "| **Question type**\t\t\t\t | Action type**\t\t\t       | **Response polarity**\t\t    | **Responses to alternative questions**  | **Explicit-implicit (dis)confirmation**\t  | **Response type**\t\t\t   | **Annotator comment**\t\t\t\t\t       | **Turn-initial particle**\n",
                "|------------------------------------------------|---------------------------------------------|------------------------------------|-----------------------------------------|-------------------------------------------|----------------------------------------|-------------------------------------------------------------------|-------------------------------------\n",
                "| Polar question [P]\t\t\t\t | Information-seeking question [Q]\t       | Responses to polar questions:\t    | First alternative [A]\t\t      | Explicit (yes/no, direct repeat) [E]\t  | Type-conforming (yes/no; A or B) [TC]  | Points to potentially follow-up; notes on more complex cases      | um, uh, ah, oh, well, look, mm, no, \n",
                "| Alternative question [A]\t\t\t | Request (permission-seeking question) [R]   | Yes [Y]\t\t\t    | Second alternative [B]\t\t      | Implicit [I]\t\t\t\t  | Non-type-conforming\n",
                "| Q-word question [Q]\t\t\t\t | Assertion [A]\t\t\t       | No [N]\t\t\t\t    | Neither [N]\n",
                "| False positive (i.e. not a question) [FP]\t | Suggestion [S]\t\t\t       | Yes-no [YN]\n",
                "|------------------------------------------------|---------------------------------------------|------------------------------------|-----------------------------------------|-------------------------------------------|----------------------------------------|-------------------------------------------------------------------|-------------------------------------\t\t\t\t\t\t\t\t\t\t\t       | Non-answer [NA]\n",
                "\n",
                "\n",
                "\n",
                "# Data Exploration and Analysis\n",
                "\n",
                "We now load the manually annotated data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_ann <- openxlsx::read.xlsx(here::here(\"tables\", \"ufors_annotated.xlsx\"), sheet = 1)\n",
                "# inspect\n",
                "ufor_ann %>%\n",
                "  dplyr::filter(corpus == \"The La Trobe Corpus of Spoken Australian English\") %>%\n",
                "  head() %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can use and edit the code chunk below to inspect other instances of utterance-final *or* by changing the identifier of the instance, e.g., from `instance 1` (which is the default below) to `instance 51` (overall, there are 98).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "ufor_ann %>%\n",
                "  dplyr::filter(hit == \"instance 1\") %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now generate an overview table showing us how frequent different combinations are in the raw data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_ann %>%\n",
                "  dplyr::group_by(hit) %>%\n",
                "  tidyr::fill(action.type, .direction = \"updown\") %>%\n",
                "  tidyr::fill(question.type, .direction = \"updown\") %>%\n",
                "  tidyr::fill(response.polarity, .direction = \"updown\") %>%\n",
                "  tidyr::fill(`explicit-inferred`, .direction = \"updown\") %>%\n",
                "  tidyr::fill(response.type, .direction = \"updown\") %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  group_by(action.type, question.type, response.polarity, `explicit-inferred`, response.type) %>% \n",
                "  dplyr::summarise(Frequency = n()) %>%\n",
                "  dplyr::arrange(-Frequency) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "> It is important to note that there are false positives in the data, i.e. instances that do not really represent instances of utterance-final *or*. Hence, we will remove all instances representing false positives but also non-canonical uses of utterance-final *or* from the data as the analysis will focus on canonical uses of utterance-final *or*. Cononical instances are where the *or* is part of a ploar question.\n",
                "\n",
                "## Canonical (Q-P) Instances\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "ufor_can <- ufor_ann %>%\n",
                "  dplyr::group_by(hit) %>%\n",
                "  tidyr::fill(action.type, .direction = \"updown\") %>%\n",
                "  tidyr::fill(question.type, .direction = \"updown\") %>%\n",
                "  tidyr::fill(response.polarity, .direction = \"updown\") %>%\n",
                "  tidyr::fill(`explicit-inferred`, .direction = \"updown\") %>%\n",
                "  tidyr::fill(response.type, .direction = \"updown\") %>%\n",
                "  # filter canonical instances\n",
                "  dplyr::filter(action.type == \"Q\" & question.type == \"P\")\n",
                "# inspect\n",
                "knitr::kable(head(ufor_can))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We check how many instances of utterance-final *or* are left.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "length(names(table(ufor_can$hit)))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We are left with 57 canonical instances of utterance-final *or* (i.e. where the utterance containing utterance-final *or* is an information seeking question (Q) and a polar question (P).\n",
                "\n",
                "\n",
                "We will now check, what instances are left in the data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "names(table(ufor_can$hit))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can use and edit the code chunk below to inspect other instances of utterance-final *or* by changing the identifier of the instance, e.g., from `instance 1` (which is the default below) to `instance 9` (overall, there are 57).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "ufor_can %>%\n",
                "  dplyr::filter(hit == \"instance 1\") %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now generate an overview table showing us how frequent different combinations are in the canonical data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_can %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  group_by(action.type, question.type, response.polarity, `explicit-inferred`, response.type) %>% \n",
                "  dplyr::summarise(Frequency = n()) %>%\n",
                "  dplyr::arrange(-Frequency) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Canonical with Y or N response\n",
                "\n",
                "We now want to check the instances where the canonical sequence has received either a positive *yes* [Y] or a negative *no* [N] responses.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_can_yn <- ufor_can %>%\n",
                "  dplyr::filter(response.polarity == \"Y\" | response.polarity == \"N\")\n",
                "# inspect\n",
                "knitr::kable(head(ufor_can_yn))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Again, we will now check, how many instances are left in the data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "length(names(table(ufor_can_yn$hit)))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We see that there are 46 instances left of canonical sequences where the response is positive or negative.\n",
                "\n",
                "We will now check, what instances are left in the data.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "names(table(ufor_can_yn$hit))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can use and edit the code chunk below to inspect other instances of utterance-final *or* with positive and negative responses by changing the identifier of the instance, e.g., from `instance 1` (which is the default below) to `instance 82` (overall, there are 46).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "ufor_can_yn %>%\n",
                "  dplyr::filter(hit == \"instance 1\") %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now generate an overview table showing us how frequent different combinations are in the canonical data  with positive and negative responses.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_can_yn %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  group_by(action.type, question.type, response.polarity, `explicit-inferred`, response.type) %>% \n",
                "  dplyr::summarise(Frequency = n()) %>%\n",
                "  dplyr::arrange(-Frequency) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Canonical with explicit Y or N response\n",
                "\n",
                "We now want to check the instances where the canonical sequence has received either an **explicit** positive *yes* [Y] or negative *no* [N] responses.\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_can_eyn <- ufor_can_yn %>%\n",
                "  dplyr::filter(`explicit-inferred` == \"E\")\n",
                "# inspect\n",
                "knitr::kable(head(ufor_can_eyn))\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Again, we will now check, how many instances are left in the data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "length(names(table(ufor_can_eyn$hit)))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Also, we check, what instances are left in the data.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "names(table(ufor_can_eyn$hit))\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "You can use and edit the code chunk below to inspect other instances of utterance-final *or* with positive and negative responses by changing the identifier of the instance, e.g., from `instance 1` (which is the default below) to `instance 75` (overall, there are 37).\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# inspect\n",
                "ufor_can_eyn %>%\n",
                "  dplyr::filter(hit == \"instance 1\") %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We will now generate an overview table showing us how frequent different combinations are in the canonical data  with explicit positive and negative responses.\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "ufor_can_eyn %>%\n",
                "  dplyr::filter(context == \"hit\") %>%\n",
                "  group_by(action.type, question.type, response.polarity, `explicit-inferred`, response.type) %>% \n",
                "  dplyr::summarise(Frequency = n()) %>%\n",
                "  dplyr::arrange(-Frequency) %>%\n",
                "  knitr::kable()\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Outro\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "sessionInfo()\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "\n",
                "\n"
            ]
        }
    ],
    "metadata": {
        "anaconda-cloud": "",
        "kernelspec": {
            "display_name": "R",
            "langauge": "R",
            "name": "ir"
        },
        "language_info": {
            "codemirror_mode": "r",
            "file_extension": ".r",
            "mimetype": "text/x-r-source",
            "name": "R",
            "pygments_lexer": "r",
            "version": "3.4.1"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}
